{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lx2rx9QmbR5z"
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing,metrics \n",
    "from haversine import haversine\n",
    "from datetime import datetime\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "import warnings\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split,KFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor\n",
    "from sklearn.linear_model import LogisticRegression,Lasso,LinearRegression, Ridge,BayesianRidge\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
    "from sklearn.cluster import KMeans \n",
    "from sklearn.svm import SVR\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "from geopy import distance\n",
    "%matplotlib inline\n",
    "from scipy.spatial import distance as scidist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "colab_type": "code",
    "id": "Lk0f6Ou4bR53",
    "outputId": "ac93918e-a715-4f62-cc56-1cde73f527e3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load training, weather and holidays data \n",
    "train_data = pd.read_csv('train.csv')\n",
    "wd = pd.read_csv('weather.csv')\n",
    "holidays_data = pd.read_csv('holidays.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute is_holiday\n",
    "def compute_holiday(row):\n",
    "    if row['day_of_year'] in holidays_data['day_of_year']:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3-pmoAKtbR57"
   },
   "outputs": [],
   "source": [
    "# weather features: merge with train_data\n",
    "wd = wd.replace({\"precipitation\": {\"T\":0.01}, \"snow fall\": {\"T\":0.01}, \"snow depth\": {\"T\":0.1}})\n",
    "\n",
    "wd['date'] = pd.to_datetime(wd['date'], format='%d-%m-%Y')\n",
    "wd['day_of_year'] = wd['date'].dt.dayofyear\n",
    "\n",
    "holidays_data['date'] = pd.to_datetime(holidays_data['date'])\n",
    "holidays_data['day_of_year'] = holidays_data['date'].dt.dayofyear\n",
    "\n",
    "train_data['pickup_datetime'] = pd.to_datetime(train_data['pickup_datetime'])\n",
    "train_data['day_of_year'] = train_data['pickup_datetime'].dt.dayofyear\n",
    "train_data = pd.merge(train_data, wd, on='day_of_year')\n",
    "\n",
    "train_data['is_holiday'] = train_data.apply(compute_holiday, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 326
    },
    "colab_type": "code",
    "id": "-mAfZ6HRbR59",
    "outputId": "c839d787-41ac-430c-e0e6-b23cb892cd0f"
   },
   "outputs": [],
   "source": [
    "# rush hours features\n",
    "# Add is_weekend ? is_work_hour ? features.\n",
    "train_data['pickup_datetime'] = pd.to_datetime(train_data['pickup_datetime']) \n",
    "train_data['dropoff_datetime'] = pd.to_datetime(train_data['dropoff_datetime']) \n",
    "\n",
    "train_data['pickup_hours'] = train_data['pickup_datetime'].dt.hour\n",
    "train_data['pickup_day'] = train_data['pickup_datetime'].dt.weekday\n",
    "train_data['dropoff_hours'] = train_data['dropoff_datetime'].dt.hour\n",
    "\n",
    "weekends = np.where(train_data['pickup_day'] > 4, 1, 0)\n",
    "train_data['is_weekend'] = weekends\n",
    "\n",
    "lower_hrs = np.where(train_data['pickup_hours'] > 7, 1, 0)\n",
    "upper_hrs = np.where(train_data['dropoff_hours'] < 9, 1, 0)\n",
    "work_hours = np.where(lower_hrs == upper_hrs, lower_hrs, 0)\n",
    "train_data['is_rush_hour_am'] = work_hours\n",
    "\n",
    "lower_hrs = np.where(train_data['pickup_hours'] > 16, 1, 0)\n",
    "upper_hrs = np.where(train_data['dropoff_hours'] < 18, 1, 0)\n",
    "work_hours = np.where(lower_hrs == upper_hrs, lower_hrs, 0)\n",
    "train_data['is_rush_hour_pm'] = work_hours\n",
    "\n",
    "# drop all temps created\n",
    "train_data.drop(labels=['pickup_day'], axis=1, inplace=True)\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "colab_type": "code",
    "id": "T4pPLz2xbR6A",
    "outputId": "8b8dc0d0-d1d5-4770-a195-3b1b7ee286cd"
   },
   "outputs": [],
   "source": [
    "#drop uneceessary features\n",
    "train_data.drop(labels=['id','pickup_datetime','dropoff_datetime', \n",
    "                        'date'], axis=1, inplace=True)\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "nbriBtSbbR6H",
    "outputId": "bcc58b60-0f1d-4cee-9296-6264ce3841b7"
   },
   "outputs": [],
   "source": [
    "# check for missing column values and check data shape\n",
    "missing_train = train_data.isnull().mean().sort_values(ascending=False)\n",
    "print(missing_train.head(5))\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yN-iIWJlbR6K"
   },
   "source": [
    "# Additional Features Choice \n",
    "- Distance to Empire State Building ::\n",
    "located on East 34th Street between 5th Ave. and FDR Dr., one of the most popular corridors for traffic in North America ==> Empire State Building Location: (40.748940, -73.985625)\n",
    "https://patch.com/new-york/new-york-city/nyc-worlds-third-worst-city-traffic-congestion\n",
    "The location is also one of the most visited in NYC for tourism: https://www.planetware.com/tourist-attractions-/new-york-city-us-ny-nyc.htm\n",
    "\n",
    "- Distance to Bryant Park ::\n",
    "located on East 42nd Street which is also mentioned in the article as one of the busiest spots. Location is also a famous touristic area right before FDR Dr. ==> Bryant: (40.753318, -73.982734)\n",
    "https://patch.com/new-york/new-york-city/nyc-worlds-third-worst-city-traffic-congestion\n",
    "\n",
    "- Distance to Financial District ::\n",
    "lot of people commute there because of work and business. During rush hours, expecting significant number of people trying to go there thereby increasing the trip duration ==> FD (40.707697, -74.008291)\n",
    "\n",
    "- Times Square ==> (40.758901, -73.985136) Some of the most visited places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TAiwDKx9qMpH"
   },
   "outputs": [],
   "source": [
    "# Helper functions for distance calculations\n",
    "def fromPickUpHelper(row, lat, lon):\n",
    "    u = [row['pickup_latitude'], row['pickup_longitude']]\n",
    "    v = [lat, lon]\n",
    "    return scidist.euclidean(u, v)\n",
    "#   return haversine((row['pickup_latitude'], row['pickup_longitude']), (lat, lon))\n",
    "\n",
    "def toDestinationHelper(row, lat, lon):\n",
    "    u = [row['dropoff_latitude'], row['dropoff_longitude']]\n",
    "    v = [lat, lon]\n",
    "    return scidist.euclidean(u, v)\n",
    "#   return haversine((row['dropoff_latitude'], row['dropoff_longitude']), (lat, lon))\n",
    "\n",
    "def euclideanDist(row):\n",
    "    u = [row['pickup_latitude'], row['pickup_longitude']]\n",
    "    v = [row['dropoff_latitude'], row['dropoff_longitude']]\n",
    "    return scidist.euclidean(u, v)\n",
    "\n",
    "def manhattanDist(row):\n",
    "    u = [row['pickup_latitude'], row['pickup_longitude']]\n",
    "    v = [row['dropoff_latitude'], row['dropoff_longitude']]\n",
    "    return scidist.cityblock(u, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Euclidean Distance\n",
    "train_data['euclidean_dist'] = train_data.apply(euclideanDist, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manhattan Distance\n",
    "train_data['manhattan_dist'] = train_data.apply(manhattanDist, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V_x2n_VIbR6L"
   },
   "outputs": [],
   "source": [
    "# geodesic distance feature\n",
    "td_geodes = [] \n",
    "train_dist = []\n",
    "\n",
    "for index, row in train_data.iterrows():\n",
    "    dist_train = haversine([row['pickup_latitude'],row['pickup_longitude']],[row['dropoff_latitude'],row['dropoff_longitude']])\n",
    "    geodesic_dist = distance.distance((row['pickup_latitude'], row['pickup_longitude']), (row['dropoff_latitude'], row['dropoff_longitude'])).km\n",
    "\n",
    "    train_dist.append(dist_train)\n",
    "    td_geodes.append(geodesic_dist)\n",
    "train_data['geodesic_dist'] = td_geodes\n",
    "train_data['haversine_dist'] = train_dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "d8w7XVPDbR6P",
    "outputId": "37d156e4-c20e-4450-92cc-26f4771f28fb"
   },
   "outputs": [],
   "source": [
    "#analyze and remove outliers\n",
    "max_dist_train = np.max([train_data['geodesic_dist']])\n",
    "print(\"Max_dist\", max_dist_train)\n",
    "min_dist_train = np.min([train_data['geodesic_dist']])\n",
    "print(\"Min_dist\",min_dist_train)\n",
    "mean_dist_train = np.mean([train_data['geodesic_dist']])\n",
    "print(\"Mean_dist\",mean_dist_train)\n",
    "train_data['geodesic_dist'].describe()\n",
    "dist_std_train = np.std(train_data['geodesic_dist'])\n",
    "train_data = train_data[train_data['geodesic_dist'] <= mean_dist_train + 2*dist_std_train]\n",
    "train_data = train_data[train_data['geodesic_dist'] >= mean_dist_train - 2*dist_std_train]\n",
    "train_data['geodesic_dist'].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vW2a_1S3wAb2"
   },
   "outputs": [],
   "source": [
    "# Compute distance of pickup to busy areas in Manhattan\n",
    "fd = (40.707697, -74.008291) #financial district\n",
    "bryant_park= (40.753318, -73.982734)\n",
    "times_sq = (40.758901, -73.985136) \n",
    "ctrl_park = (40.783043, -73.965244)\n",
    "empire_state = (40.748940, -73.985625)\n",
    "memorial_911 = (40.711495, -74.013440)\n",
    "\n",
    "train_data['pickup_dist_FD'] = train_data.apply(fromPickUpHelper, args=fd, axis=1)\n",
    "train_data['pickup_dist_bryant_park'] = train_data.apply(fromPickUpHelper, args=bryant_park, axis=1)\n",
    "train_data['pickup_dist_times_square'] = train_data.apply(fromPickUpHelper, args=times_sq, axis=1)\n",
    "train_data['pickup_dist_central_park'] = train_data.apply(fromPickUpHelper, args=ctrl_park, axis=1)\n",
    "train_data['pickup_dist_empire_state'] = train_data.apply(fromPickUpHelper, args=empire_state, axis=1)\n",
    "train_data['pickup_dist_memorial_911'] = train_data.apply(fromPickUpHelper, args=memorial_911, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "colab_type": "code",
    "id": "NTbLnnbQwteP",
    "outputId": "72b552aa-762b-4df2-bb8b-a3bc5f020f52"
   },
   "outputs": [],
   "source": [
    "# Compute distance of destination to busy areas in Manhattan\n",
    "train_data['dropoff_dist_FD'] = train_data.apply(toDestinationHelper, args=fd, axis=1)\n",
    "train_data['dropoff_dist_bryant_park'] = train_data.apply(toDestinationHelper, args=bryant_park, axis=1)\n",
    "train_data['dropoff_dist_times_square'] = train_data.apply(toDestinationHelper, args=times_sq, axis=1)\n",
    "train_data['dropoff_dist_central_park'] = train_data.apply(toDestinationHelper, args=ctrl_park, axis=1)\n",
    "train_data['dropoff_dist_empire_state'] = train_data.apply(toDestinationHelper, args=empire_state, axis=1)\n",
    "train_data['dropoff_dist_memorial_911'] = train_data.apply(toDestinationHelper, args=memorial_911, axis=1)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0U0brno_bR6S"
   },
   "outputs": [],
   "source": [
    "#encoding necessary features and randomly sample to reduce dataset size\n",
    "train_data = train_data.replace({\"store_and_fwd_flag\": {\"N\":0, \"Y\":1}})\n",
    "# train_data = train_data.sample(frac=0.05,random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "lX62excebR6V",
    "outputId": "5c5d2c7e-8a04-488a-d7f3-b5c846f28e4c"
   },
   "outputs": [],
   "source": [
    "#transforming duration to log scale to allow for RMSE plus spliting data\n",
    "train_data['log_duration'] = np.log(train_data['trip_duration'].values + 1)\n",
    "train_data.drop(labels=['trip_duration'], axis=1, inplace=True)\n",
    "train_target = pd.DataFrame(train_data['log_duration'])\n",
    "train_data.drop('log_duration', axis = 1, inplace = True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.array(train_data), np.array(train_target), test_size=0.30)\n",
    "eval_set=[(X_test, y_test)]\n",
    "print(\"train_target: \", train_target.shape)\n",
    "print('train_set: ', X_train.shape, y_train.shape)\n",
    "print('test_set: ', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1240
    },
    "colab_type": "code",
    "id": "7z80NedUbR6Y",
    "outputId": "34d57300-65cf-4977-946d-2a42254935a1"
   },
   "outputs": [],
   "source": [
    "# Visualization of lon, lat\n",
    "fig, ax = plt.subplots(ncols=1, nrows=1,figsize=(12,10))\n",
    "plt.ylim(40.5, 41)\n",
    "plt.xlim(-74.1, -73.7)\n",
    "ax.set_xlabel('longitude')\n",
    "ax.set_ylabel('latitude')\n",
    "ax.set_title('Scatter plot of pickup locations in New York City')\n",
    "ax.scatter(train_data['pickup_longitude'],train_data['pickup_latitude'], s=0.1, color='black')\n",
    "\n",
    "fig, ax = plt.subplots(ncols=1, nrows=1,figsize=(12,10))\n",
    "plt.ylim(40.5, 40.9)\n",
    "plt.xlim(-74.2, -73.6)\n",
    "ax.set_xlabel('longitude')\n",
    "ax.set_ylabel('latitude')\n",
    "ax.set_title('Scatter plot of dropoff locations in New York City')\n",
    "ax.scatter(train_data['dropoff_longitude'],train_data['dropoff_latitude'], s=0.1, color='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "xL_9qDKqbR6c",
    "outputId": "910a8732-21ce-4015-9b26-207e847ca8be"
   },
   "outputs": [],
   "source": [
    "#Random Forest\n",
    "random_forest_regressor= RandomForestRegressor(n_estimators = 100, n_jobs = 4)\n",
    "random_forest_regressor.fit(X_train, y_train)\n",
    "rf_y_pred = random_forest_regressor.predict(X_test)\n",
    "random_forest_error =  np.sqrt(mean_squared_error(y_test, rf_y_pred))\n",
    "print(\"Test error: \", random_forest_error)\n",
    "print(y_test[0:10])\n",
    "print(rf_y_pred[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 915
    },
    "colab_type": "code",
    "id": "-J_oESCLbR6f",
    "outputId": "08feb218-b92a-4fb5-b79c-63878a8ce0cd"
   },
   "outputs": [],
   "source": [
    "0#Feature importance\n",
    "fig, ax = plt.subplots()\n",
    "width = 0.6\n",
    "feature_importances = pd.DataFrame(random_forest_regressor.feature_importances_, index = train_data.columns, columns = ['Importance']).sort_values('Importance', ascending = False)\n",
    "print(feature_importances)\n",
    "ax.bar(np.arange(len(train_data.columns)), random_forest_regressor.feature_importances_, width, color='b')\n",
    "ax.set_xticks(np.arange(len(random_forest_regressor.feature_importances_)))\n",
    "ax.set_xticklabels(train_data.columns.values, rotation = 90, horizontalalignment='right')\n",
    "plt.title('Feature Importances')\n",
    "ax.set_ylabel('Normalized Gini Importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "wuT7WjRfbR6j",
    "outputId": "ca64daba-939e-45e4-e852-c4c98173cd39"
   },
   "outputs": [],
   "source": [
    "#XGBoost\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtrain.save_binary('train.buffer')\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "dtest.save_binary('test.buffer')\n",
    "evallist = [(dtest, 'eval'), (dtrain, 'train')]\n",
    "param = {'min_child_weight': 3, 'eta': 0.9, 'colsample_bytree': 0.6, 'max_depth': 6,\n",
    "            'subsample': 0.9, 'lambda': 1., 'nthread': -1,'booster' : 'gbtree',\n",
    "            'eval_metric': 'rmse', 'objective': 'reg:linear'}\n",
    "bst = xgb.train(param, dtrain, 100, evallist, early_stopping_rounds=2, maximize=False, verbose_eval=1)\n",
    "print('Modeling RMSLE %.5f' % bst.best_score)\n",
    "pred = bst.predict(dtest, ntree_limit=bst.best_ntree_limit)\n",
    "pred = np.exp(pred) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "o09JJ3mDbR6n",
    "outputId": "384c6e73-04f9-416d-86b9-6668dea1d734"
   },
   "outputs": [],
   "source": [
    "#Multi-layer perceptron\n",
    "multi_layer_perceptron_regressor = MLPRegressor(solver='lbfgs', alpha = 1e-5, hidden_layer_sizes = (5, 2), random_state = 1)\n",
    "multi_layer_perceptron_regressor.fit(X_train, y_train)     \n",
    "mlp_y_pred = multi_layer_perceptron_regressor.predict(X_test)\n",
    "mlp_error = np.sqrt(mean_squared_error(y_test, mlp_y_pred))\n",
    "print(\"Test error: \", mlp_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qmasvodObR6s",
    "outputId": "495c14d5-6cf8-4612-fe45-1662898c2e70"
   },
   "outputs": [],
   "source": [
    "#Multi-layer perceptron with Adam solver + changed hyperparams\n",
    "multi_layer_perceptron_regressor_2 = MLPRegressor(hidden_layer_sizes=(200,), activation='relu', solver='adam', alpha=0.0001, batch_size='auto', learning_rate='constant', learning_rate_init=0.001, power_t=0.5, max_iter=200, shuffle=True, random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum = True, early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08,n_iter_no_change = 10)\n",
    "multi_layer_perceptron_regressor_2.fit(X_train, y_train)     \n",
    "mlp_y_pred_2 = multi_layer_perceptron_regressor_2.predict(X_test)\n",
    "mlp_error_2 = np.sqrt(mean_squared_error(y_test, mlp_y_pred_2))\n",
    "print(\"Test error: \", mlp_error_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "j6OAWYlqbR6v",
    "outputId": "a4caa837-19ac-4d0d-d9ce-e4d5745c662d"
   },
   "outputs": [],
   "source": [
    "#svm using various kernels\n",
    "svm_kernel_err = []\n",
    "kernels = ['rbf']\n",
    "for curr_kernel in kernels:\n",
    "    print('Running...', curr_kernel)\n",
    "    if curr_kernel == 'poly':\n",
    "        model_svm = SVR(kernel= curr_kernel, degree=3)\n",
    "    else:\n",
    "        model_svm = SVR(kernel= curr_kernel)\n",
    "    model_svm.fit(X_train, y_train)\n",
    "    svm_pred = model_svm.predict(X_test)\n",
    "    svm_pred_error = np.sqrt(mean_squared_error(y_test, svm_pred))\n",
    "    print(curr_kernel)\n",
    "    print(\"Test error: \", svm_pred_error)\n",
    "    svm_kernel_err.append(svm_pred_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 236
    },
    "colab_type": "code",
    "id": "XC2ditVNbR60",
    "outputId": "9e7d559b-8272-479f-d257-e4bae47d15d4"
   },
   "outputs": [],
   "source": [
    "err_list = [random_forest_error, bst.best_score, mlp_error_2, svm_kernel_err[-1]]\n",
    "x = np.arange(4)\n",
    "plt.bar(x, height=err_list, color='green')\n",
    "plt.xticks(x, ['random_forrest', 'xgb', 'mlp_error_2', 'gaussian_svm'])\n",
    "plt.ylabel('RMSLE score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hg4U_V3zbR63"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Taxi Trip project.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
